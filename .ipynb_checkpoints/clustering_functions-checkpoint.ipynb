{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(traj_loc, pdb_loc, sieve_res=2, sieve_traj=10,threshold=0.6):\n",
    "    traj = md.load_dcd(traj_loc,top=pdb_loc)\n",
    "    topfile=traj.top\n",
    "    feat = coor.featurizer(topfile)\n",
    "    residues = np.arange(0,topfile.n_residues)\n",
    "    pairs = []                                                                                 \n",
    "    for i,r1 in enumerate(residues):\n",
    "        for r2 in residues[i+1::2]:\n",
    "            pairs.append([r1,r2])\n",
    "    pairs = np.array(pairs)\n",
    "    feature=feat.add_residue_mindist(pairs, scheme='closest-heavy',threshold=threshold,periodic=False)\n",
    "    inp = pyemma.coordinates.load(traj_loc, features=feat)\n",
    "    inp = inp[::sieve_traj]\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_simi_matrix(inp,simi_index='no_scaled',batch_size=1000000):\n",
    "    all_input = list(itertools.combinations(inp, 2))\n",
    "    batch_size=1000000\n",
    "    inp_sliced=[all_input[i*batch_size:(i+1)*batch_size] for i in range(int(len(all_input)/batch_size))]\n",
    "    if int(len(inp_sliced)) < len(all_input)/batch_size:\n",
    "        inp_sliced.append(all_input[len(inp_sliced)*batch_size:])\n",
    "    for i in range(len(inp_sliced)):\n",
    "        temp_start = time.time()\n",
    "        temp_c = np.zeros((int(len(inp_sliced[i])),3))\n",
    "        temp_input = np.array(inp_sliced[i])\n",
    "        product = temp_input.reshape(-1,2,temp_input.shape[-1]).sum(1)\n",
    "        for row in range(3):\n",
    "            temp_c[:,row] = np.sum(product==row,axis=1)\n",
    "        if i == 0:\n",
    "            all_c = temp_c\n",
    "        else:\n",
    "            all_c = np.concatenate((all_c,temp_c),axis=0)\n",
    "    ###calculate similarity\n",
    "    simi = all_c[:,0]+all_c[:,2]\n",
    "    ###try Faith\n",
    "    disimi = all_c[:,1]\n",
    "    denominate = all_c[:,0]+all_c[:,1]+all_c[:,2]\n",
    "    w_p = simi/denominate\n",
    "    simi_matrix = np.zeros((len(inp),len(inp)))\n",
    "    indices = np.triu_indices(len(inp),k=1)\n",
    "    indices = (indices[1],indices[0])\n",
    "    simi_matrix[indices] = simi\n",
    "    return simi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative(inp,simi_matrix):\n",
    "    df = pd.DataFrame(simi_matrix,columns=pd.MultiIndex.from_tuples([('{}'.format(i),'{}'.format(i)) for i in range(1,len(inp)+1)],names=['cluster', 'frame']))\n",
    "    inp_copy=inp\n",
    "    dic={}\n",
    "    hie_tree=[]\n",
    "    dentrom=[]\n",
    "    while df.shape[0] > 2:\n",
    "        ###update df\n",
    "        frame_column=[i[1] for i in df.columns.to_list()]\n",
    "        hie_tree.append(frame_column)\n",
    "        new_max=np.argmax(df, axis=None)     ###2.5s\n",
    "\n",
    "        del_index = np.unravel_index(new_max, df.shape)\n",
    "        max_value = df.to_numpy()[del_index[0]][del_index[1]] ###0.1s\n",
    "\n",
    "        ###get temp inp\n",
    "        delete_row=[int(i) for i in df.columns[del_index[0]][1].split(',') ]\n",
    "        delete_cluster_row=[int(i) for i in df.columns[del_index[0]][0].split(',')]\n",
    "        delete_column=[int(i) for i in df.columns[del_index[1]][1].split(',') ]\n",
    "        delete_cluster_column=[int(i) for i in df.columns[del_index[1]][0].split(',')]\n",
    "        dentrom.append([*delete_cluster_column,*delete_cluster_row])\n",
    "\n",
    "        delete_all=delete_column+delete_row\n",
    "        insert_index='{}'.format(delete_all)[1:-1]   ###0.1s\n",
    "        insert_cluster_index='{}'.format(2*len(inp) - df.shape[0]+1)\n",
    "        df.drop(columns=[('{}'.format(delete_cluster_column)[1:-1],'{}'.format(delete_column)[1:-1]),('{}'.format(delete_cluster_row)[1:-1],'{}'.format(delete_row)[1:-1])],axis=1,inplace=True)\n",
    "        df.drop(index=[*del_index],axis=0,inplace=True)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        temp_w_sim=[]            ###1s\n",
    "\n",
    "        ###get temp inp\n",
    "        frame_column=[i[1] for i in df.columns.to_list() ]\n",
    "        columns=[[int(d) for d in [*i.split(',')]] for i in frame_column]\n",
    "        temp_inp=[[inp_copy[d-1] for d in m] for m in columns]    ###0.1s\n",
    "\n",
    "        ###perform comparison\n",
    "        for i in temp_inp:\n",
    "            compare=bc(np.concatenate(([inp_copy[d-1] for d in delete_all],i),axis=0))\n",
    "            temp_w_sim.append(compare.total_w_sim)         ###1s\n",
    "\n",
    "        temp_w_sim=[0]+temp_w_sim\n",
    "        df.loc[-1] = [0]*df.shape[1] # adding a row\n",
    "        df.index = df.index + 1  # shifting index\n",
    "        df = df.sort_index()  # sorting by index\n",
    "        df.insert(loc=0, column=(insert_cluster_index,insert_index), value=temp_w_sim)\n",
    "        dic[insert_index]=max_value\n",
    "    dentrogram = np.vstack(dentrom)-np.ones((1,2))\n",
    "    values = np.array([*dic.values()],ndmin=2)\n",
    "    num_frames = np.array([len(i) for i in [[int(d) for d in [*k.split(',')]] for k in list(dic.keys())]],ndmin=2)\n",
    "    tree = np.hstack((dentrogram,values.T,num_frames.T))\n",
    "    last_two = [int(i[0]) for i in df.columns.to_list()]\n",
    "    tree = np.vstack((tree, [[last_two[0],last_two[1],df.to_numpy()[1][0],len(inp)]]))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
