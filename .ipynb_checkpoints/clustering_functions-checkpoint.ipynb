{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemma\n",
    "import numpy as np\n",
    "import pyemma.coordinates as coor\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from matplotlib.pyplot import cm\n",
    "from collections import OrderedDict\n",
    "import mdtraj as md\n",
    "import itertools\n",
    "import time\n",
    "import indices\n",
    "from indices.base import BaseComparisons as bc\n",
    "from indices.faith import Faith as Fai\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot\n",
    "import mdtraj\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(traj_loc, pdb_loc, sieve_res=2, sieve_traj=10,threshold=0.6):\n",
    "    '''\n",
    "    Contact fingeprint calculation.\n",
    "    ---\n",
    "    Input:\n",
    "    traj_loc, pdb_loc: trajectory and pdb file location.\n",
    "    sieve_res: calculate contact fingerprint every \"sieve_res\" (e.g. every two residue),\n",
    "               default=2\n",
    "    sieve_traj: calculate fingerprints every \"sieve_traj\" sample.\n",
    "               default=10\n",
    "    threshold: criterion for every \"sieve_res\" contact, within threshold 1 and 0 otherwise.\n",
    "               default=0.6\n",
    "    \n",
    "    Output:\n",
    "    inp: contact fingerprints for selected samples\n",
    "    '''\n",
    "    traj = md.load_dcd(traj_loc,top=pdb_loc)\n",
    "    topfile=traj.top\n",
    "    feat = coor.featurizer(topfile)\n",
    "    residues = np.arange(0,topfile.n_residues)\n",
    "    pairs = []                                                                                 \n",
    "    for i,r1 in enumerate(residues):\n",
    "        for r2 in residues[i+1::2]:\n",
    "            pairs.append([r1,r2])\n",
    "    pairs = np.array(pairs)\n",
    "    feature=feat.add_residue_mindist(pairs, scheme='closest-heavy',threshold=threshold,periodic=False)\n",
    "    inp = pyemma.coordinates.load(traj_loc, features=feat)\n",
    "    inp = inp[::sieve_traj]\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_simi_matrix(inp,simi_scale='no_scaled',batch_size=1000000):\n",
    "    '''\n",
    "    Binary similarity matrix calculation.\n",
    "    ---\n",
    "    Input:\n",
    "    inp: sample contact fingerprints with size np.array((n,m)). n is number of samples \n",
    "         and m is the length of each fingerprint.\n",
    "    simi_scale: select which scale index for similarity calculation.\n",
    "                default: simply add all 1 and all 0 together\n",
    "    batch_size: calculate simi_matrix in batches if number of samples are too large.\n",
    "                default=1000000\n",
    "    \n",
    "    Output:\n",
    "    simi_matrix: similarity matrix with size np.array((n,n)).\n",
    "    '''\n",
    "    all_input = list(itertools.combinations(inp, 2))\n",
    "    batch_size=1000000\n",
    "    inp_sliced=[all_input[i*batch_size:(i+1)*batch_size] for i in range(int(len(all_input)/batch_size))]\n",
    "    if int(len(inp_sliced)) < len(all_input)/batch_size:\n",
    "        inp_sliced.append(all_input[len(inp_sliced)*batch_size:])\n",
    "    for i in range(len(inp_sliced)):\n",
    "        temp_start = time.time()\n",
    "        temp_c = np.zeros((int(len(inp_sliced[i])),3))\n",
    "        temp_input = np.array(inp_sliced[i])\n",
    "        product = temp_input.reshape(-1,2,temp_input.shape[-1]).sum(1)\n",
    "        for row in range(3):\n",
    "            temp_c[:,row] = np.sum(product==row,axis=1)\n",
    "        if i == 0:\n",
    "            all_c = temp_c\n",
    "        else:\n",
    "            all_c = np.concatenate((all_c,temp_c),axis=0)\n",
    "    ###calculate similarity\n",
    "    if simi_scale == 'no_scaled':\n",
    "        simi = all_c[:,0]+all_c[:,2]\n",
    "    elif simi_scale == \"Faith\":\n",
    "        all_simi = all_c[:,0]+0.5*all_c[:,2]\n",
    "        denominate = all_c[:,0]+all_c[:,1]+all_c[:,2]\n",
    "        simi = all_simi/denominate\n",
    "    simi_matrix = np.zeros((len(inp),len(inp)))\n",
    "    indices = np.triu_indices(len(inp),k=1)\n",
    "    indices = (indices[1],indices[0])\n",
    "    simi_matrix[indices] = simi\n",
    "    return simi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative(inp,simi_matrix):\n",
    "    '''\n",
    "    Perform agglomerative hierachical clustering.\n",
    "    ---\n",
    "    Input:\n",
    "    inp: sample contact fingerprints with size np.array((n,m)). n is number of samples \n",
    "         and m is the length of each fingerprint.\n",
    "    simi_matrix: binary similarity matrix with size np.array((n,n)).\n",
    "    \n",
    "    Output: \n",
    "    tree: clustering results for constructing dentrogram in scipy style.\n",
    "    hie_tree: sample index in each cluster along clustering process.\n",
    "    dic: record which two sets are grouped together.\n",
    "    '''\n",
    "    df = pd.DataFrame(simi_matrix,columns=pd.MultiIndex.from_tuples([('{}'.format(i),'{}'.format(i)) for i in range(1,len(inp)+1)],names=['cluster', 'frame']))\n",
    "    inp_copy=inp\n",
    "    dic={}\n",
    "    hie_tree=[]\n",
    "    dentrom=[]\n",
    "    while df.shape[0] > 2:\n",
    "        ###update df\n",
    "        frame_column=[i[1] for i in df.columns.to_list()]\n",
    "        hie_tree.append(frame_column)\n",
    "        new_max=np.argmax(df, axis=None)     ###2.5s\n",
    "\n",
    "        del_index = np.unravel_index(new_max, df.shape)\n",
    "        max_value = df.to_numpy()[del_index[0]][del_index[1]] ###0.1s\n",
    "\n",
    "        ###get temp inp\n",
    "        delete_row=[int(i) for i in df.columns[del_index[0]][1].split(',') ]\n",
    "        delete_cluster_row=[int(i) for i in df.columns[del_index[0]][0].split(',')]\n",
    "        delete_column=[int(i) for i in df.columns[del_index[1]][1].split(',') ]\n",
    "        delete_cluster_column=[int(i) for i in df.columns[del_index[1]][0].split(',')]\n",
    "        dentrom.append([*delete_cluster_column,*delete_cluster_row])\n",
    "\n",
    "        delete_all=delete_column+delete_row\n",
    "        insert_index='{}'.format(delete_all)[1:-1]   ###0.1s\n",
    "        insert_cluster_index='{}'.format(2*len(inp) - df.shape[0]+1)\n",
    "        df.drop(columns=[('{}'.format(delete_cluster_column)[1:-1],'{}'.format(delete_column)[1:-1]),('{}'.format(delete_cluster_row)[1:-1],'{}'.format(delete_row)[1:-1])],axis=1,inplace=True)\n",
    "        df.drop(index=[*del_index],axis=0,inplace=True)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        temp_w_sim=[]            ###1s\n",
    "\n",
    "        ###get temp inp\n",
    "        frame_column=[i[1] for i in df.columns.to_list()]\n",
    "        columns=[[int(d) for d in [*i.split(',')]] for i in frame_column]\n",
    "        temp_inp=[[inp_copy[d-1] for d in m] for m in columns]    ###0.1s\n",
    "\n",
    "        ###perform comparison\n",
    "        for i in temp_inp:\n",
    "            compare=bc(np.concatenate(([inp_copy[d-1] for d in delete_all],i),axis=0))\n",
    "            temp_w_sim.append(compare.total_w_sim)         ###1s\n",
    "\n",
    "        temp_w_sim=[0]+temp_w_sim\n",
    "        df.loc[-1] = [0]*df.shape[1] # add a row\n",
    "        df.index = df.index + 1  # shift index\n",
    "        df = df.sort_index()  # sort by index\n",
    "        df.insert(loc=0, column=(insert_cluster_index,insert_index), value=temp_w_sim)\n",
    "        dic[insert_index]=max_value\n",
    "    dentrogram = np.vstack(dentrom)-np.ones((1,2))\n",
    "    values = np.array([*dic.values()],ndmin=2)\n",
    "    num_frames = np.array([len(i) for i in [[int(d) for d in [*k.split(',')]] for k in list(dic.keys())]],ndmin=2)\n",
    "    tree = np.hstack((dentrogram,values.T,num_frames.T))\n",
    "    last_two = [int(i[0]) for i in df.columns.to_list()]\n",
    "    tree = np.vstack((tree, [[last_two[0]-1,last_two[1]-1,df.to_numpy()[1][0],len(inp)]]))\n",
    "    return tree, hie_tree, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simi_threshold(tree,p,min_simi,save=False):\n",
    "    '''\n",
    "    Plot scipy.dentrogram tree.\n",
    "    ---\n",
    "    Input: \n",
    "    tree: clustering results for constructing dentrogram in scipy style with size np.array((n,4)).\n",
    "    p: show last p steps clustering results.\n",
    "    mini_simi: minimum similarity for clustering results.\n",
    "    save: check if saving figure.\n",
    "          default: False\n",
    "    \n",
    "    Output:\n",
    "    scipy.dentrogram tree figure.\n",
    "    '''\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    dend = shc.dendrogram(tree,p=p,truncate_mode='lastp')\n",
    "    plt.axhline(y=70, color='r', linestyle='-')\n",
    "    plt.xlabel('Num_samples')\n",
    "    plt.ylabel('Simi_value')\n",
    "    if save:\n",
    "        plt.savefig('simi_threshold_tree.png')\n",
    "\n",
    "def plot_test_result(true_rmsd,hie_tree,cluster_step,save=False):\n",
    "    '''\n",
    "    Plot 1d rmsd validation figure with sample ratio bar.\n",
    "    ---\n",
    "    Input:\n",
    "    true_rmsd: rmsd wrt reference pdb with size np.array((1,n)).\n",
    "    hie_tree: sample index in each cluster along clustering process.\n",
    "    cluster_step: check clustering results for selected step.\n",
    "    save: check if saving figure.\n",
    "          default=False\n",
    "          \n",
    "    Output:\n",
    "    1d rmsd validation figure with sample ratio bar.\n",
    "    label_index: sample index in each cluster for selected cluster_step.\n",
    "    '''\n",
    "    colors = ['grey', 'purple', 'blue', 'green', 'orange', 'red',\n",
    "             'black','brown','navy','indigo','cyan','teal','violet','royalblue','yellow']\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[15, 1]) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    label_index = [[int(i)-1 for i in hie_tree[cluster_step][d].split(',')] for d in range(len(hie_tree[cluster_step]))]\n",
    "    label_index = sorted(label_index, key=lambda x:len(x), reverse=True)\n",
    "    if len(label_index) > 10:\n",
    "        label_index = label_index[:10]\n",
    "    test_rmsd = [[true_rmsd[i] for i in label_index[d]] for d in range(len(label_index))]\n",
    "    for index,i in enumerate(test_rmsd):\n",
    "        ax0.scatter(label_index[index],i,marker='.',color=colors[index])\n",
    "    percentage=[len(i)/len(true_rmsd) for i in test_rmsd]\n",
    "    sum_percentage = [0.0]+[sum(percentage[:i]) for i in range(1,len(percentage))]+[1.0]\n",
    "    ax0.set_xlabel('Sample')\n",
    "    ax0.set_ylabel('RMSD')\n",
    "    cmap = mpl.colors.ListedColormap(colors[:len(test_rmsd)])\n",
    "    norm = mpl.colors.BoundaryNorm(sum_percentage, cmap.N)\n",
    "    cb2 = mpl.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                    norm=norm,\n",
    "                                    boundaries=sum_percentage,\n",
    "                                    ticks=sum_percentage+[1.0],\n",
    "                                    spacing='proportional')\n",
    "    cb2.set_label('Cluster samples ratio')\n",
    "    if save:\n",
    "        plt.savefig('1d_rmsd_validation.png')\n",
    "    return label_index\n",
    "\n",
    "def plot_2d_rmsd(traj_file,pdb_file,label_index,indices='backbone',sieve=1,save=False):\n",
    "    '''\n",
    "    Plot 2d rmsd validation for selected cluster_step.\n",
    "    ---\n",
    "    Input:\n",
    "    traj_file, pdb_file: trajectory and pdb file location.\n",
    "    label_index: sample index in each cluster for selected cluster_step.\n",
    "    indices: select indices to perform rmsd calculation.\n",
    "    sieve: calculate fingerprints every \"sieve_traj\" sample.\n",
    "           default=1 \n",
    "    save: check if saving figure.\n",
    "          default=False\n",
    "          \n",
    "    Output:\n",
    "    2d rmsd validation figure with rmsd side bar.\n",
    "    '''\n",
    "    label_concate = np.concatenate(label_index)\n",
    "    traj = md.load_dcd(traj_file,top=pdb_file)\n",
    "    topfile=traj.top\n",
    "    pdb=md.load_pdb(pdb_file)\n",
    "    if indices == 'backbone':\n",
    "        all_CA=topfile.select(\"backbone==1\")\n",
    "    elif indices == 'all C':\n",
    "        all_CA=topfile.select(\"type C\")\n",
    "    else:\n",
    "        all_CA=None\n",
    "    traj_cluster=traj[::sieve][label_concate]\n",
    "    rmsd_2d=np.zeros((len(traj_cluster),len(traj_cluster)))\n",
    "    upper_indices = np.triu_indices(len(traj_cluster),k=0)\n",
    "    lower_indices = (upper_indices[1],upper_indices[0])\n",
    "    r2d = []\n",
    "    for i in range(len(traj_cluster)):\n",
    "        r2d.append(md.rmsd(traj_cluster[i:],traj_cluster[i],atom_indices=all_CA))\n",
    "    rmsd_2d[lower_indices] = np.concatenate(r2d)\n",
    "    rmsd_2d[upper_indices] = np.concatenate(r2d)\n",
    "    sns.heatmap(rmsd_2d*10,square=True,xticklabels=100,yticklabels=100,cmap='bwr',cbar_kws={'label':'RMSD'},vmin=0,vmax=10)\n",
    "    plt.plot(range(len(traj_cluster)),range(len(traj_cluster)),'-.',color='k',linewidth=2)\n",
    "    plt.xlabel(\"Frame #\")\n",
    "    plt.ylabel(\"Frame #\")\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(direction='out')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('2d_rmsd_validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_accuracy(traj_loc, pdb_loc, dic, indices='backbone',sieve_traj=1, save=False):\n",
    "    '''\n",
    "    Plot accuracy for each clustering step.\n",
    "    ---\n",
    "    Input:\n",
    "    traj_loc, pdb_loc: trajectory and pdb file location.\n",
    "    sieve_traj: calculate fingerprints every \"sieve_traj\" sample.\n",
    "                default=1\n",
    "    dic: record which two sets are grouped together.\n",
    "    '''\n",
    "    traj = md.load_dcd(traj_loc,top=pdb_loc)\n",
    "    topfile=traj.top\n",
    "    traj = traj[::sieve_traj]\n",
    "    all_clust=[[int(d) for d in [*i.split(',')]] for i in list(dic.keys())]\n",
    "    ave_rmsd = []\n",
    "    all_rmsd = []\n",
    "    if indices == 'backbone':\n",
    "        all_CA=topfile.select(\"backbone==1\")\n",
    "    elif indices == 'all C':\n",
    "        all_CA=topfile.select(\"type C\")\n",
    "    else:\n",
    "        all_CA=None\n",
    "    for index,i in enumerate(all_clust):   \n",
    "        traj_comp=traj[[np.array(i)-1]]\n",
    "        rmsd=md.rmsd(traj_comp,pdb,atom_indices=all_CA)\n",
    "        ave_rmsd.append(np.average(rmsd))\n",
    "        all_rmsd.append(rmsd)\n",
    "    accuracy=[]\n",
    "    for i in range(len(all_rmsd)):\n",
    "        if len(all_rmsd[i])>1:\n",
    "            ratio = correct_ratio(all_rmsd[i])\n",
    "            accuracy.append(np.max(ratio))\n",
    "    num_frames = np.array([len(i) for i in [[int(d) for d in [*k.split(',')]] for k in list(dic.keys())]],ndmin=2)\n",
    "    plt.scatter(range(len(accuracy)),accuracy,marker='.',color='b')\n",
    "    plt.scatter(range(num_frames.shape[1]),*(num_frames/num_frames.shape[1]).tolist(),color='r')\n",
    "    plt.xlabel('Cluster_step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    if save:\n",
    "        plt.savefig('cluster_accuracy.png')\n",
    "\n",
    "        \n",
    "def correct_ratio(x,cluster_range):\n",
    "    all_ratio = []\n",
    "    for i in range(len(cluster_range)-1):\n",
    "        all_ratio.append(np.sum((x>cluster_range[i]) & (x<cluster_range[i+1]))/x.shape[0])\n",
    "    all_ratio.append(sum(all_ratio))\n",
    "    ratio = [round(i,4) for i in all_ratio]\n",
    "    return ratio"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
